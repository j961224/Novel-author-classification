{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"glove+CNN_biLSTM.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"iVDWx0eDEwjn"},"source":["## 데이터 불러오기"]},{"cell_type":"code","metadata":{"id":"kXPvHo639PUt"},"source":["# 라이브러리\n","from matplotlib import rcParams, pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","from pathlib import Path\n","import re\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import StratifiedKFold\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.utils import plot_model, to_categorical\n","from tensorflow.keras.optimizers import Adam\n","import warnings \n","warnings.filterwarnings(action='ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipDRk54G9uGv"},"source":["#경로 설정\n","import os\n","os.chdir('/content/Writing_Style')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oBuuirDr9xfQ"},"source":["#파일 불러오기\n","train = pd.read_csv('/content/train.csv', encoding = 'utf-8')\n","test = pd.read_csv('/content/test_x.csv', encoding = 'utf-8')\n","sample_submission = pd.read_csv('/content/sample_submission.csv', encoding = 'utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"m99xR8gc-Hm3","outputId":"6eb9ca9f-ecf2-4d0c-ea33-223f012b74b4"},"source":["#train 데이터 살펴보기\n","train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>He was almost choking. There was so much, so m...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>“Your sister asked for it, I suppose?”</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>She was engaged one day as she walked, in per...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>The captain was in the porch, keeping himself ...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>54874</th>\n","      <td>54874</td>\n","      <td>“Is that you, Mr. Smith?” odin whispered. “I h...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>54875</th>\n","      <td>54875</td>\n","      <td>I told my plan to the captain, and between us ...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>54876</th>\n","      <td>54876</td>\n","      <td>\"Your sincere well-wisher, friend, and sister...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54877</th>\n","      <td>54877</td>\n","      <td>“Then you wanted me to lend you money?”</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>54878</th>\n","      <td>54878</td>\n","      <td>It certainly had not occurred to me before, bu...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>54879 rows × 3 columns</p>\n","</div>"],"text/plain":["       index                                               text  author\n","0          0  He was almost choking. There was so much, so m...       3\n","1          1             “Your sister asked for it, I suppose?”       2\n","2          2   She was engaged one day as she walked, in per...       1\n","3          3  The captain was in the porch, keeping himself ...       4\n","4          4  “Have mercy, gentlemen!” odin flung up his han...       3\n","...      ...                                                ...     ...\n","54874  54874  “Is that you, Mr. Smith?” odin whispered. “I h...       2\n","54875  54875  I told my plan to the captain, and between us ...       4\n","54876  54876   \"Your sincere well-wisher, friend, and sister...       1\n","54877  54877            “Then you wanted me to lend you money?”       3\n","54878  54878  It certainly had not occurred to me before, bu...       0\n","\n","[54879 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"lqx13alb-K9z","outputId":"6730491e-b63e-448a-ffb2-f4e4dc407abe"},"source":["#test 데이터 살펴보기\n","test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>“Not at all. I think she is one of the most ch...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>As the lady had stated her intention of scream...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>“And then suddenly in the silence I heard a so...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>His conviction remained unchanged. So far as I...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19612</th>\n","      <td>19612</td>\n","      <td>At the end of another day or two, odin growing...</td>\n","    </tr>\n","    <tr>\n","      <th>19613</th>\n","      <td>19613</td>\n","      <td>All afternoon we sat together, mostly in silen...</td>\n","    </tr>\n","    <tr>\n","      <th>19614</th>\n","      <td>19614</td>\n","      <td>odin, having carried his thanks to odin, proc...</td>\n","    </tr>\n","    <tr>\n","      <th>19615</th>\n","      <td>19615</td>\n","      <td>Soon after this, upon odin's leaving the room,...</td>\n","    </tr>\n","    <tr>\n","      <th>19616</th>\n","      <td>19616</td>\n","      <td>And all the worse for the doomed man, that the...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>19617 rows × 2 columns</p>\n","</div>"],"text/plain":["       index                                               text\n","0          0  “Not at all. I think she is one of the most ch...\n","1          1  \"No,\" replied he, with sudden consciousness, \"...\n","2          2  As the lady had stated her intention of scream...\n","3          3  “And then suddenly in the silence I heard a so...\n","4          4  His conviction remained unchanged. So far as I...\n","...      ...                                                ...\n","19612  19612  At the end of another day or two, odin growing...\n","19613  19613  All afternoon we sat together, mostly in silen...\n","19614  19614   odin, having carried his thanks to odin, proc...\n","19615  19615  Soon after this, upon odin's leaving the room,...\n","19616  19616  And all the worse for the doomed man, that the...\n","\n","[19617 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"VwUarY98-N2A","outputId":"6b6cdf55-e7e2-4ecd-e6c0-7038db70aa2a"},"source":["#sample_submission\n","sample_submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19612</th>\n","      <td>19612</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19613</th>\n","      <td>19613</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19614</th>\n","      <td>19614</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19615</th>\n","      <td>19615</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19616</th>\n","      <td>19616</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>19617 rows × 6 columns</p>\n","</div>"],"text/plain":["       index  0  1  2  3  4\n","0          0  0  0  0  0  0\n","1          1  0  0  0  0  0\n","2          2  0  0  0  0  0\n","3          3  0  0  0  0  0\n","4          4  0  0  0  0  0\n","...      ... .. .. .. .. ..\n","19612  19612  0  0  0  0  0\n","19613  19613  0  0  0  0  0\n","19614  19614  0  0  0  0  0\n","19615  19615  0  0  0  0  0\n","19616  19616  0  0  0  0  0\n","\n","[19617 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"DW7qquxoE1eo"},"source":["## 전처리"]},{"cell_type":"code","metadata":{"id":"h82daThn-QbP"},"source":["#부호를 제거해주는 함수\n","def alpha_num(text):\n","    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n","\n","train['text']=train['text'].apply(alpha_num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"m8lL3RJY-TII","outputId":"2d4e9d17-ed8e-46e2-e2e9-e5fad11572e3"},"source":["#부호가 사라진 것을 확인할 수 있습니다.\n","train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>He was almost choking There was so much so muc...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Your sister asked for it I suppose</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>She was engaged one day as she walked in peru...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>The captain was in the porch keeping himself c...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Have mercy gentlemen odin flung up his hands D...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>54874</th>\n","      <td>54874</td>\n","      <td>Is that you Mr Smith odin whispered I hardly d...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>54875</th>\n","      <td>54875</td>\n","      <td>I told my plan to the captain and between us w...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>54876</th>\n","      <td>54876</td>\n","      <td>Your sincere wellwisher friend and sister LUC...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54877</th>\n","      <td>54877</td>\n","      <td>Then you wanted me to lend you money</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>54878</th>\n","      <td>54878</td>\n","      <td>It certainly had not occurred to me before but...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>54879 rows × 3 columns</p>\n","</div>"],"text/plain":["       index                                               text  author\n","0          0  He was almost choking There was so much so muc...       3\n","1          1                 Your sister asked for it I suppose       2\n","2          2   She was engaged one day as she walked in peru...       1\n","3          3  The captain was in the porch keeping himself c...       4\n","4          4  Have mercy gentlemen odin flung up his hands D...       3\n","...      ...                                                ...     ...\n","54874  54874  Is that you Mr Smith odin whispered I hardly d...       2\n","54875  54875  I told my plan to the captain and between us w...       4\n","54876  54876   Your sincere wellwisher friend and sister LUC...       1\n","54877  54877               Then you wanted me to lend you money       3\n","54878  54878  It certainly had not occurred to me before but...       0\n","\n","[54879 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"YqwiP36n-Uzc"},"source":["# 불용어 제거해주는 함수\n","def remove_stopwords(text):\n","    final_text = []\n","    for i in text.split():\n","        if i.strip().lower() not in stopwords:\n","            final_text.append(i.strip())\n","    return \" \".join(final_text)\n","\n","# 불용어\n","stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n","             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n","             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n","             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n","             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n","             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n","             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n","             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n","             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n","             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n","             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lLI48hM9-Yr8"},"source":["#전처리 적용\n","train['text'] = train['text'].str.lower()\n","test['text'] = test['text'].str.lower()\n","train['text'] = train['text'].apply(alpha_num).apply(remove_stopwords)\n","test['text'] = test['text'].apply(alpha_num).apply(remove_stopwords)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYgnWJhvG7gn","outputId":"844101fe-9065-4606-8df9-de08463cf36f"},"source":["X_train = train['text'].values\n","Y_train = train['author'].values\n","\n","X_test = test['text'].values\n","print(X_train.shape, X_test.shape, Y_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(54879,) (19617,) (54879,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osoLFitG-ei_","outputId":"ee39f86d-4137-455b-bf87-c26b5cebba7b"},"source":["X_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['almost choking much much wanted say strange exclamations came lips pole gazed fixedly bundle notes hand looked odin evident perplexity',\n","       'sister asked suppose',\n","       'engaged one day walked perusing janes last letter dwelling passages proved jane not written spirits instead surprised mr odin saw looking odin meeting putting away letter immediately forcing smile said',\n","       ..., 'sincere wellwisher friend sister lucy odin',\n","       'wanted lend money', 'certainly not occurred said yes like'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"sGGXceo5HAdm"},"source":["### 토크나이징"]},{"cell_type":"code","metadata":{"id":"XucxQEhLHD5M"},"source":["# keras의 Tokenizer 사용\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)\n","word_index = tokenizer.word_index\n","vocab_size = len(word_index) + 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FV-xRrpFEAhg"},"source":["## 벡터화"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dCpxk7TmDbHp","outputId":"96c91d3f-6efe-4838-c14a-141db64f44dc"},"source":["# keras의 texts_to_sequences 사용\n","train_sequences = tokenizer.texts_to_sequences(X_train)\n","train_max_len=max(len(l) for l in train_sequences)\n","\n","test_sequences = tokenizer.texts_to_sequences(X_test)\n","test_max_len=max(len(l) for l in test_sequences)\n","\n","print(train_max_len, test_max_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["211 199\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3AAM94rTDdV_","outputId":"8ad0fdf9-b6de-42cb-f981-3e2c37126e35"},"source":["# 최대길이에 맞춰 패딩 처리\n","padding_type='post'\n","\n","train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=train_max_len)\n","test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=train_max_len)\n","print(train_padded.shape, test_padded.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(54879, 211) (19617, 211)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PO8SbeHeFSet"},"source":["## 임베딩\n","\n","> word2vec & glove 두 방식으로 임베딩\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3JLW2PQoFfFB"},"source":["* glove 임베딩 기법"]},{"cell_type":"code","metadata":{"id":"GVS9r3CcC9_r"},"source":["embedding_dict= dict()\n","f = open('/content/glove.6B.100d.txt', encoding='utf8')\n","\n","for line in f:\n","    word_vector = line.split()\n","    word = word_vector[0]\n","    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n","    embedding_dict[word] = word_vector_arr\n","f.close\n","\n","embedding_matrix = np.zeros((vocab_size, 100))\n","\n","for word, i in word_index.items():\n","    temp = embedding_dict.get(word)\n","    if temp is not None:\n","        embedding_matrix[i] = temp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-c9YaxOPHha8"},"source":["### k-fold 교차검증"]},{"cell_type":"code","metadata":{"id":"Utt9EYLUHf3_"},"source":["# k-fold 교차검증\n","# Stratified K-fold 교차 검증 방법은 원본 데이터에서 레이블 분포를 먼저 고려한 뒤, 이 분포와 동일하게 학습 및 검증 데이터 세트를 분배한다.\n","n_fold = 5\n","n_class = 5\n","seed = 42\n","cross_validation = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0dZoht01jyEJ"},"source":["## 모델 학습\n","\n","> glove + CNN 예측 모델\n","\n","activatino = swish\n","\n"]},{"cell_type":"code","metadata":{"id":"YdmlzIy8jwTk"},"source":["def get_model():\n","    model = Sequential([\n","        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=train_max_len),\n","        Dropout(.5),\n","        Conv1D(128, 7, padding=\"valid\", activation=\"swish\", strides=3),\n","        Conv1D(128, 7, padding=\"valid\", activation=\"swish\", strides=3),\n","        Conv1D(128, 7, padding=\"valid\", activation=\"swish\", strides=3),\n","        GlobalMaxPooling1D(),\n","        Dense(128, activation='swish'),\n","        Dropout(.5),\n","        Dense(n_class, activation='softmax')\n","    ])\n","    \n","    # compile model\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=Adam(learning_rate=.007))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L85oBuHujxZ_","outputId":"ef4ade46-bd99-454c-fcb6-54205ccc68aa"},"source":["p_validation = np.zeros((train_padded.shape[0], n_class))\n","p_test = np.zeros((test_padded.shape[0], n_class))\n","for i, (i_train, i_validation) in enumerate(cross_validation.split(train_padded, Y_train), 1):\n","    \n","    print(f'\\n training model for 교차검증 # {i}번째 \\n')\n","    \n","    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n","                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n","    \n","    print(f'학습인덱스 : {i_train} | 학습데이터에 사용되는 데이터 : {len(i_train)}')\n","    print(f'검증인덱스 : {i_validation} | 검증에 사용하는 데이터 : {len(i_validation)}\\n')\n","    print('-' * 90)\n","    \n","    class_model = get_model()    \n","    history = class_model.fit(train_padded[i_train], \n","            to_categorical(Y_train[i_train]), # 범주형으로 \n","            validation_data=(train_padded[i_validation], to_categorical(Y_train[i_validation])),\n","            epochs=10,\n","            batch_size=512,\n","            callbacks=[es])\n","    p_validation[i_validation, :] = class_model.predict(train_padded[i_validation])\n","    p_test += class_model.predict(test_padded) / n_fold\n","    print('-' * 90)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," training model for 교차검증 # 1번째 \n","\n","학습인덱스 : [    0     1     2 ... 54876 54877 54878] | 학습데이터에 사용되는 데이터 : 43903\n","검증인덱스 : [    9    12    16 ... 54850 54855 54860] | 검증에 사용하는 데이터 : 10976\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 97s 1s/step - loss: 1.5013 - val_loss: 1.0901\n","Epoch 2/10\n","86/86 [==============================] - 96s 1s/step - loss: 1.0277 - val_loss: 0.8792\n","Epoch 3/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.7734 - val_loss: 0.7890\n","Epoch 4/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.6279 - val_loss: 0.7704\n","Epoch 5/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.5213 - val_loss: 0.7727\n","Epoch 6/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.4611 - val_loss: 0.7908\n","Epoch 7/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.3979 - val_loss: 0.8356\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","------------------------------------------------------------------------------------------\n","\n"," training model for 교차검증 # 2번째 \n","\n","학습인덱스 : [    0     1     2 ... 54874 54877 54878] | 학습데이터에 사용되는 데이터 : 43903\n","검증인덱스 : [    3     5    10 ... 54869 54875 54876] | 검증에 사용하는 데이터 : 10976\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 96s 1s/step - loss: 1.4695 - val_loss: 1.0508\n","Epoch 2/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.9756 - val_loss: 0.8652\n","Epoch 3/10\n","86/86 [==============================] - 95s 1s/step - loss: 0.7349 - val_loss: 0.7915\n","Epoch 4/10\n","86/86 [==============================] - 95s 1s/step - loss: 0.6036 - val_loss: 0.7873\n","Epoch 5/10\n","86/86 [==============================] - 95s 1s/step - loss: 0.5069 - val_loss: 0.7842\n","Epoch 6/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.9860 - val_loss: 0.8336\n","Epoch 7/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.4985 - val_loss: 0.8645\n","Epoch 8/10\n","86/86 [==============================] - 96s 1s/step - loss: 0.4043 - val_loss: 0.8712\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","------------------------------------------------------------------------------------------\n","\n"," training model for 교차검증 # 3번째 \n","\n","학습인덱스 : [    0     1     3 ... 54875 54876 54878] | 학습데이터에 사용되는 데이터 : 43903\n","검증인덱스 : [    2     7     8 ... 54872 54873 54877] | 검증에 사용하는 데이터 : 10976\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 95s 1s/step - loss: 1.5235 - val_loss: 1.0464\n","Epoch 2/10\n","86/86 [==============================] - 94s 1s/step - loss: 1.0163 - val_loss: 0.8652\n","Epoch 3/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.7697 - val_loss: 0.8152\n","Epoch 4/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.6194 - val_loss: 0.7869\n","Epoch 5/10\n","86/86 [==============================] - 93s 1s/step - loss: 0.5258 - val_loss: 0.7824\n","Epoch 6/10\n","86/86 [==============================] - 93s 1s/step - loss: 0.4495 - val_loss: 2.6142\n","Epoch 7/10\n","86/86 [==============================] - 93s 1s/step - loss: 1.7399 - val_loss: 1.0009\n","Epoch 8/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.6968 - val_loss: 0.8360\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","------------------------------------------------------------------------------------------\n","\n"," training model for 교차검증 # 4번째 \n","\n","학습인덱스 : [    2     3     4 ... 54876 54877 54878] | 학습데이터에 사용되는 데이터 : 43903\n","검증인덱스 : [    0     1    13 ... 54852 54854 54867] | 검증에 사용하는 데이터 : 10976\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 94s 1s/step - loss: 1.4996 - val_loss: 1.0668\n","Epoch 2/10\n","86/86 [==============================] - 93s 1s/step - loss: 1.0085 - val_loss: 0.8683\n","Epoch 3/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.7641 - val_loss: 0.7802\n","Epoch 4/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.6167 - val_loss: 0.7506\n","Epoch 5/10\n","86/86 [==============================] - 95s 1s/step - loss: 0.5243 - val_loss: 0.7591\n","Epoch 6/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.4495 - val_loss: 0.7468\n","Epoch 7/10\n","86/86 [==============================] - 95s 1s/step - loss: 0.3876 - val_loss: 0.7768\n","Epoch 8/10\n","86/86 [==============================] - 95s 1s/step - loss: 0.3674 - val_loss: 0.8161\n","Epoch 9/10\n","86/86 [==============================] - 95s 1s/step - loss: 0.3520 - val_loss: 0.8477\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","------------------------------------------------------------------------------------------\n","\n"," training model for 교차검증 # 5번째 \n","\n","학습인덱스 : [    0     1     2 ... 54875 54876 54877] | 학습데이터에 사용되는 데이터 : 43904\n","검증인덱스 : [    4     6    17 ... 54871 54874 54878] | 검증에 사용하는 데이터 : 10975\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 96s 1s/step - loss: 1.4999 - val_loss: 1.0242\n","Epoch 2/10\n","86/86 [==============================] - 95s 1s/step - loss: 0.9957 - val_loss: 0.8249\n","Epoch 3/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.7469 - val_loss: 0.7647\n","Epoch 4/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.5967 - val_loss: 0.7361\n","Epoch 5/10\n","86/86 [==============================] - 94s 1s/step - loss: 0.5107 - val_loss: 0.7769\n","Epoch 6/10\n","86/86 [==============================] - 93s 1s/step - loss: 0.4457 - val_loss: 0.7671\n","Epoch 7/10\n","86/86 [==============================] - 93s 1s/step - loss: 0.4029 - val_loss: 0.8408\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","------------------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXhR66eWj4lS","outputId":"fc8ed2f2-aaa9-43b2-a0cf-cd30049035f6"},"source":["print(f'Accuracy (CV): {accuracy_score(Y_train, np.argmax(p_validation, axis=1)) * 100:8.4f}%')\n","print(f'Log Loss (CV): {log_loss(pd.get_dummies(Y_train), p_validation):8.4f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy (CV):  72.4284%\n","Log Loss (CV):   0.7640\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vIvcvEmwj6fg","outputId":"4d5aa1cb-2446-49d2-f6ce-33f49841b0c5"},"source":["# model summary\n","print(class_model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 211, 100)          4713700   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 211, 100)          0         \n","_________________________________________________________________\n","conv1d_12 (Conv1D)           (None, 69, 128)           89728     \n","_________________________________________________________________\n","conv1d_13 (Conv1D)           (None, 21, 128)           114816    \n","_________________________________________________________________\n","conv1d_14 (Conv1D)           (None, 5, 128)            114816    \n","_________________________________________________________________\n","global_max_pooling1d_4 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 128)               16512     \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 5)                 645       \n","=================================================================\n","Total params: 5,050,217\n","Trainable params: 5,050,217\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UTh6uomrsRE3"},"source":["## 모델 학습_2\n","\n","> glove + Bi-LSTM 예측 모델\n","\n"]},{"cell_type":"code","metadata":{"id":"yg0GtCm8C-LN"},"source":["# 학습파라미터 (학습률, 에폭수)\n","lr = 0.007\n","epoch_val = 10\n","\n","def get_model():\n","    model = Sequential([\n","        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=train_max_len),\n","        Bidirectional(LSTM(64, return_sequences=True)),\n","        Bidirectional(LSTM(64)),\n","        Dense(n_class, activation='softmax')\n","    ])\n","    \n","    # compile model\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=Adam(learning_rate=lr))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkD78UawNsF-","outputId":"7b0b7ede-d819-4001-a352-949d1e034a8c"},"source":["p_validation = np.zeros((train_padded.shape[0], n_class))\n","p_test = np.zeros((test_padded.shape[0], n_class))\n","for i, (i_train, i_validation) in enumerate(cross_validation.split(train_padded, Y_train), 1):\n","    \n","    print(f'\\n training model for 교차검증 # {i}번째 \\n')\n","    \n","    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n","                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n","    \n","    print(f'학습인덱스 : {i_train} | 학습데이터에 사용되는 데이터 : {len(i_train)}')\n","    print(f'검증인덱스 : {i_validation} | 검증에 사용하는 데이터 : {len(i_validation)}\\n')\n","    print('-' * 90)\n","    \n","    class_model = get_model()    \n","    history = class_model.fit(train_padded[i_train], \n","            to_categorical(Y_train[i_train]), # 범주형으로 \n","            validation_data=(train_padded[i_validation], to_categorical(Y_train[i_validation])),\n","            epochs=epoch_val,\n","            batch_size=512,\n","            callbacks=[es])\n","    p_validation[i_validation, :] = class_model.predict(train_padded[i_validation])\n","    p_test += class_model.predict(test_padded) / n_fold\n","    print('-' * 90)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," training model for 교차검증 # 1번째 \n","\n","학습인덱스 : [    0     1     2 ... 54876 54877 54878] | 학습데이터에 사용되는 데이터 : 43903\n","검증인덱스 : [    9    12    16 ... 54850 54855 54860] | 검증에 사용하는 데이터 : 10976\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 430s 5s/step - loss: 1.2949 - val_loss: 0.7937\n","Epoch 2/10\n","86/86 [==============================] - 421s 5s/step - loss: 0.5295 - val_loss: 0.7019\n","Epoch 3/10\n","86/86 [==============================] - 415s 5s/step - loss: 0.3238 - val_loss: 0.7643\n","Epoch 4/10\n","86/86 [==============================] - 418s 5s/step - loss: 0.2414 - val_loss: 0.8891\n","Epoch 5/10\n","86/86 [==============================] - 432s 5s/step - loss: 0.2055 - val_loss: 0.9487\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","------------------------------------------------------------------------------------------\n","\n"," training model for 교차검증 # 2번째 \n","\n","학습인덱스 : [    0     1     2 ... 54874 54877 54878] | 학습데이터에 사용되는 데이터 : 43903\n","검증인덱스 : [    3     5    10 ... 54869 54875 54876] | 검증에 사용하는 데이터 : 10976\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 431s 5s/step - loss: 1.2942 - val_loss: 0.7867\n","Epoch 2/10\n","86/86 [==============================] - 417s 5s/step - loss: 0.5342 - val_loss: 0.7231\n","Epoch 3/10\n","86/86 [==============================] - 415s 5s/step - loss: 0.3207 - val_loss: 0.7851\n","Epoch 4/10\n","86/86 [==============================] - 419s 5s/step - loss: 0.2374 - val_loss: 0.8864\n","Epoch 5/10\n","86/86 [==============================] - 422s 5s/step - loss: 0.1967 - val_loss: 0.9700\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","------------------------------------------------------------------------------------------\n","\n"," training model for 교차검증 # 3번째 \n","\n","학습인덱스 : [    0     1     3 ... 54875 54876 54878] | 학습데이터에 사용되는 데이터 : 43903\n","검증인덱스 : [    2     7     8 ... 54872 54873 54877] | 검증에 사용하는 데이터 : 10976\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 438s 5s/step - loss: 1.2951 - val_loss: 0.7519\n","Epoch 2/10\n","86/86 [==============================] - 498s 6s/step - loss: 0.5282 - val_loss: 0.7000\n","Epoch 3/10\n","86/86 [==============================] - 465s 5s/step - loss: 0.3264 - val_loss: 0.7778\n","Epoch 4/10\n","86/86 [==============================] - 476s 6s/step - loss: 0.2418 - val_loss: 0.8725\n","Epoch 5/10\n","86/86 [==============================] - 492s 6s/step - loss: 0.2017 - val_loss: 0.9723\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","------------------------------------------------------------------------------------------\n","\n"," training model for 교차검증 # 4번째 \n","\n","학습인덱스 : [    2     3     4 ... 54876 54877 54878] | 학습데이터에 사용되는 데이터 : 43903\n","검증인덱스 : [    0     1    13 ... 54852 54854 54867] | 검증에 사용하는 데이터 : 10976\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 537s 6s/step - loss: 1.2839 - val_loss: 0.7517\n","Epoch 2/10\n","86/86 [==============================] - 505s 6s/step - loss: 0.5306 - val_loss: 0.6977\n","Epoch 3/10\n","86/86 [==============================] - 541s 6s/step - loss: 0.3197 - val_loss: 0.7634\n","Epoch 4/10\n","86/86 [==============================] - 520s 6s/step - loss: 0.2419 - val_loss: 0.8781\n","Epoch 5/10\n","86/86 [==============================] - 486s 6s/step - loss: 0.1954 - val_loss: 0.9610\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","------------------------------------------------------------------------------------------\n","\n"," training model for 교차검증 # 5번째 \n","\n","학습인덱스 : [    0     1     2 ... 54875 54876 54877] | 학습데이터에 사용되는 데이터 : 43904\n","검증인덱스 : [    4     6    17 ... 54871 54874 54878] | 검증에 사용하는 데이터 : 10975\n","\n","------------------------------------------------------------------------------------------\n","Epoch 1/10\n","86/86 [==============================] - 431s 5s/step - loss: 1.3055 - val_loss: 0.7612\n","Epoch 2/10\n","86/86 [==============================] - 430s 5s/step - loss: 0.5435 - val_loss: 0.6931\n","Epoch 3/10\n","86/86 [==============================] - 428s 5s/step - loss: 0.3217 - val_loss: 0.7521\n","Epoch 4/10\n","86/86 [==============================] - 425s 5s/step - loss: 0.2335 - val_loss: 0.8345\n","Epoch 5/10\n","86/86 [==============================] - 440s 5s/step - loss: 0.1870 - val_loss: 0.9810\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","------------------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hlttMh6K15oL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4678da05-0cf0-4284-8470-2036ef3ff1e1"},"source":["print(f'Accuracy : {accuracy_score(Y_train, np.argmax(p_validation, axis=1)) * 100:8.4f}%')\n","print(f'Log Loss : {log_loss(pd.get_dummies(Y_train), p_validation):8.4f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy :  74.1960%\n","Log Loss :   0.7032\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-xu-sfea1-sM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"50fe58f5-0198-4b42-cc17-aa82ca6dfb47"},"source":["# model summary\n","print(class_model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 211, 100)          4713700   \n","_________________________________________________________________\n","bidirectional_8 (Bidirection (None, 211, 128)          84480     \n","_________________________________________________________________\n","bidirectional_9 (Bidirection (None, 128)               98816     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 5)                 645       \n","=================================================================\n","Total params: 4,897,641\n","Trainable params: 4,897,641\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mcCLFCuZbiqv"},"source":["# glove + CNN 모델 예측 결과\n","\n","> Accuracy (CV):  72.4284%\n","\n","> Log Loss (CV):   0.7640\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eMlLyjIrbiyL"},"source":["# glove + BiLSTM 모델 예측 결과\n","\n","\n","> Accuracy :  74.1960%\n","\n","> Log Loss :   0.7032\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rC3gnDQMcEF-"},"source":["\n","\n","### glove로 임베딩하여 각각의 예측 모델에 모델링한 결과,\n","\n","### CNN보다 BiLSTM 모델이 정확도가 2% 정도 높았고, 손실율은 0.06 정도 작았습니다.\n","\n","### 그 결과, glove로 임베딩한 상황에서 BiLSTM 모델이 더욱 적합한 것을 알 수 있었습니다. \n","\n"]},{"cell_type":"code","metadata":{"id":"ZnXPQmNJb_Ie"},"source":[""],"execution_count":null,"outputs":[]}]}