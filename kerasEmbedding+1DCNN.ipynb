{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kerasEmbedding기법_CONV1D,1DCNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Oac1DPCmlfe6"},"source":["# 0. 각 성능 비교(다른 전처리와 같은 CONV1D 사용)\n","\n","\n","1.   첫 번째 전처리와 CONV1D 모델\n","  \n","  * val_loss=0.71547\n","  \n","  * log_loss=(대회log_loss: 0.54266)\n","\n","2.   기존 전처리와 CONV1D 모델\n"," \n","  * val_loss=0.80247 (대회log_loss: 0.5904662357)\n","\n","3.  첫 번째 전처리와 baseline 모델\n","\n","  * val_loss=0.71993 \n","  \n","  * log_loss=(대회log_loss: 0.5139833248)\n","\n","4.  첫 번째 전처리와 CNN(1D CNN)(병렬화X)\n","\n","  * log_loss=0.8209335820872198(0.579853373308999)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wiAE2PT1o--b"},"source":["**-> 기존 전처리보다 첫번째 전처리가 성능이 좀 더 좋다.**"]},{"cell_type":"markdown","metadata":{"id":"7HEVdqjiorXD"},"source":["# 첫번째 전처리"]},{"cell_type":"markdown","metadata":{"id":"JN0Sn48N2f36"},"source":["첫 번째 전처리란 특수문자 제거 시, 띄어쓰기만 남는 경우가 있어 그 부분을 제거"]},{"cell_type":"markdown","metadata":{"id":"RT_SCW0lo3HA"},"source":["특수 문장 및 불용어 처리"]},{"cell_type":"code","metadata":{"id":"ePagKZhto3HB","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"error","timestamp":1619593501629,"user_tz":-540,"elapsed":4223,"user":{"displayName":"정유석","photoUrl":"","userId":"06335261930596017698"}},"outputId":"9ee4a552-b15e-4453-dae4-ccce1b0219fc"},"source":["import pandas as pd \n","\n","train_dataset = pd.read_csv(\"/content/train.csv\") \n","test_dataset = pd.read_csv(\"/content/test_x.csv\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7f372a178da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/test_x.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.csv'"]}]},{"cell_type":"code","metadata":{"id":"THF19RF3o3HQ"},"source":["def remove_stopwords(text):\n","    final_text = []\n","    for i in text.split():\n","        if i.strip().lower() not in stopwords:\n","            final_text.append(i.strip())\n","    return \" \".join(final_text)\n","\n","\n","#불용어 baseline\n","stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n","             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n","             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n","             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n","             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n","             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n","             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n","             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n","             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n","             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n","             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvdb7Ny_o3HR"},"source":["train_dataset['clear_text'] = train_dataset['text'].str.lower().apply(remove_stopwords)\n","test_dataset['clear_text'] = test_dataset['text'].str.lower().apply(remove_stopwords)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvTNHCQdo3HU"},"source":["#특수 문자 제거\n","from tqdm import tqdm \n","import re \n","list1=[]\n","def get_clean_text_list(data_df): \n","  plain_text_list = list(data_df['clear_text']) \n","  clear_text_list = [] \n","  count=0\n","  for i in tqdm(range(len(plain_text_list))): \n","    plain_text = plain_text_list[i] \n","    clear_text = plain_text.replace(\"\\\\\", \"\").replace(\"\\n\", \"\") \n","    clear_text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'\\“\\”…》]', '', clear_text) \n","    if clear_text.split() == []:\n","        count += 1\n","        list1.append(i)\n","    clear_text_list.append(clear_text.lower()) \n","  print(f\"학습 데이터 중 빈 문장의 갯수 : {count}\")\n","  return clear_text_list\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvLs_K9Oo3HV","outputId":"cba702b6-900c-4e85-d858-213ed19146dd"},"source":["train_dataset['clear_text'] = get_clean_text_list(train_dataset) \n","test_dataset['clear_text'] = get_clean_text_list(test_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 54879/54879 [00:00<00:00, 136351.11it/s]\n"," 43%|████▎     | 8376/19617 [00:00<00:00, 83737.32it/s]"],"name":"stderr"},{"output_type":"stream","text":["학습 데이터 중 빈 문장의 갯수 : 44\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 19617/19617 [00:00<00:00, 78756.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["학습 데이터 중 빈 문장의 갯수 : 0\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rQtwIy4po3HW","outputId":"c16a36a2-342d-4ac5-faf5-cd77304b8948"},"source":["train_dataset.loc[train_dataset['clear_text']=='    ']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>author</th>\n","      <th>clear_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1455</th>\n","      <td>1455</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3493</th>\n","      <td>3493</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>5523</th>\n","      <td>5523</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>5985</th>\n","      <td>5985</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>8400</th>\n","      <td>8400</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>9874</th>\n","      <td>9874</td>\n","      <td>* * * * *</td>\n","      <td>3</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>12267</th>\n","      <td>12267</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>12460</th>\n","      <td>12460</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>13055</th>\n","      <td>13055</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>14698</th>\n","      <td>14698</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>15958</th>\n","      <td>15958</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>18475</th>\n","      <td>18475</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>19802</th>\n","      <td>19802</td>\n","      <td>* * * * *</td>\n","      <td>0</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>22532</th>\n","      <td>22532</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>23137</th>\n","      <td>23137</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>23211</th>\n","      <td>23211</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>23829</th>\n","      <td>23829</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>24589</th>\n","      <td>24589</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>25719</th>\n","      <td>25719</td>\n","      <td>* * * * *</td>\n","      <td>0</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>27424</th>\n","      <td>27424</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>27575</th>\n","      <td>27575</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>27811</th>\n","      <td>27811</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>28023</th>\n","      <td>28023</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>28224</th>\n","      <td>28224</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>28917</th>\n","      <td>28917</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>35594</th>\n","      <td>35594</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>35754</th>\n","      <td>35754</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>38536</th>\n","      <td>38536</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>39121</th>\n","      <td>39121</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>40152</th>\n","      <td>40152</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>43324</th>\n","      <td>43324</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>43464</th>\n","      <td>43464</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>43686</th>\n","      <td>43686</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>43706</th>\n","      <td>43706</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>47345</th>\n","      <td>47345</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>47525</th>\n","      <td>47525</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>47699</th>\n","      <td>47699</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>47783</th>\n","      <td>47783</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>49308</th>\n","      <td>49308</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>50326</th>\n","      <td>50326</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>50343</th>\n","      <td>50343</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>50963</th>\n","      <td>50963</td>\n","      <td>* * * * *</td>\n","      <td>2</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>52675</th>\n","      <td>52675</td>\n","      <td>* * * * *</td>\n","      <td>0</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>54750</th>\n","      <td>54750</td>\n","      <td>* * * * *</td>\n","      <td>4</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       index        text  author clear_text\n","1455    1455   * * * * *       2           \n","3493    3493   * * * * *       4           \n","5523    5523   * * * * *       4           \n","5985    5985   * * * * *       4           \n","8400    8400   * * * * *       2           \n","9874    9874   * * * * *       3           \n","12267  12267   * * * * *       2           \n","12460  12460   * * * * *       4           \n","13055  13055   * * * * *       4           \n","14698  14698   * * * * *       4           \n","15958  15958   * * * * *       4           \n","18475  18475   * * * * *       4           \n","19802  19802   * * * * *       0           \n","22532  22532   * * * * *       4           \n","23137  23137   * * * * *       4           \n","23211  23211   * * * * *       4           \n","23829  23829   * * * * *       4           \n","24589  24589   * * * * *       4           \n","25719  25719   * * * * *       0           \n","27424  27424   * * * * *       4           \n","27575  27575   * * * * *       4           \n","27811  27811   * * * * *       4           \n","28023  28023   * * * * *       2           \n","28224  28224   * * * * *       4           \n","28917  28917   * * * * *       4           \n","35594  35594   * * * * *       4           \n","35754  35754   * * * * *       4           \n","38536  38536   * * * * *       4           \n","39121  39121   * * * * *       4           \n","40152  40152   * * * * *       2           \n","43324  43324   * * * * *       4           \n","43464  43464   * * * * *       4           \n","43686  43686   * * * * *       2           \n","43706  43706   * * * * *       4           \n","47345  47345   * * * * *       4           \n","47525  47525   * * * * *       4           \n","47699  47699   * * * * *       2           \n","47783  47783   * * * * *       2           \n","49308  49308   * * * * *       4           \n","50326  50326   * * * * *       4           \n","50343  50343   * * * * *       4           \n","50963  50963   * * * * *       2           \n","52675  52675   * * * * *       0           \n","54750  54750   * * * * *       4           "]},"metadata":{"tags":[]},"execution_count":263}]},{"cell_type":"code","metadata":{"id":"ZvMKFMxNo3HX"},"source":["import numpy as np\n","train_dataset['clear_text'].replace('    ', np.nan, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FB8Qtzyo3HX"},"source":["train_dataset.dropna(subset=['clear_text'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWGGB_DAo3HY"},"source":["train_dataset=train_dataset.reset_index(drop=True)\n","train_dataset=train_dataset.drop(['index'],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T42cY1aqo3HZ","outputId":"fa1d3038-7e34-48c6-afe7-2a543142b63b"},"source":["import nltk \n","from nltk.corpus import stopwords \n","\n","nltk.download(\"stopwords\") \n","nltk.download(\"punkt\") \n","#불용어 한 번 더 처리 해보기(내장된 기능으로)\n","stopwords_list = stopwords.words('english')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sY9R16WXo3Ha","outputId":"ea01b632-bf75-41b6-b78b-ae8bf3ad7f98"},"source":["from nltk.tokenize import word_tokenize \n","X_train = [] \n","train_clear_text = list(train_dataset['clear_text']) \n","\n","for i in tqdm(range(len(train_clear_text))): \n","  temp = word_tokenize(train_clear_text[i]) \n","  temp = [word for word in temp if word not in stopwords_list] \n","  temp = [word for word in temp if len(word) > 1] \n","  \n","  X_train.append(temp)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 54835/54835 [00:13<00:00, 3957.52it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jS1S4Rjio3Hb","outputId":"e125a89e-9683-4247-9fd4-488aaa1e26ff"},"source":["X_test = [] \n","test_clear_text = list(test_dataset['clear_text']) \n","\n","for i in tqdm(range(len(test_clear_text))): \n","  temp = word_tokenize(test_clear_text[i]) \n","  temp = [word for word in temp if word not in stopwords_list] \n","  temp = [word for word in temp if len(word) > 1] \n","  \n","  X_test.append(temp)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 19617/19617 [00:08<00:00, 2339.97it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2mWDl3Fro3Hc","outputId":"90ce1585-30b6-4f77-e3e5-25a33317f4bf"},"source":["word_list = [] \n","for i in tqdm(range(len(X_train))): \n","  for j in range(len(X_train[i])): \n","    word_list.append(X_train[i][j]) \n","len(list(set(word_list)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 54835/54835 [00:00<00:00, 193398.29it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["48354"]},"metadata":{"tags":[]},"execution_count":270}]},{"cell_type":"code","metadata":{"id":"SpnqcaSPo3Hd"},"source":["y_train = np.array([x for x in train_dataset['author']])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O1WDTHorsSAr"},"source":["# 1. keras embedding 기법/CNN(CONV1D) 모델 적용"]},{"cell_type":"code","metadata":{"id":"6dZGhxo2udNm"},"source":["vocab_size=len(list(set(word_list)))\n","embedding_dim = 256\n","max_length = 150\n","padding_type='post'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cw3aeC620wML"},"source":["from keras_preprocessing.text import Tokenizer\n","#tokenizer에 fit \n","tokenizer = Tokenizer(num_words = vocab_size)\n","#, oov_token=oov_tok) \n","tokenizer.fit_on_texts(X_train) \n","word_index = tokenizer.word_index\n","vocab_size=len(word_index)+1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3bHo72Q1rFf","outputId":"99a77bac-0edc-4482-8e17-16b9d1777afc"},"source":["from keras_preprocessing.sequence import pad_sequences \n","#데이터를 sequence로 변환해주고 padding \n","train_sequences = tokenizer.texts_to_sequences(X_train) \n","train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length) \n","\n","test_sequences = tokenizer.texts_to_sequences(X_test) \n","test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n","\n","print(train_padded.shape, test_padded.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(54835, 150) (19617, 150)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iCoV1TMT53jz"},"source":["## CNN(Conv1D병렬) 모델링화"]},{"cell_type":"code","metadata":{"id":"RxMteBzo5mSv"},"source":["from tensorflow.keras import preprocessing\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n","import tensorflow as tf\n","\n","Input_layer = Input(shape=(max_length,))\n","embedding_layer = Embedding(vocab_size, 256, input_length = max_length)(Input_layer)\n","dropout_emb = Dropout(rate=0.5)(embedding_layer)\n","conv1 = Conv1D(filters= 256, kernel_size= 3, padding='valid',activation=tf.nn.relu)(dropout_emb)\n","pool1 = GlobalMaxPool1D()(conv1)\n","conv2 = Conv1D(filters= 256, kernel_size= 4, padding='valid',activation=tf.nn.relu)(dropout_emb)\n","pool2 = GlobalMaxPool1D()(conv2)\n","conv3 = Conv1D(filters= 256, kernel_size= 5, padding='valid',activation=tf.nn.relu)(dropout_emb)\n","pool3 = GlobalMaxPool1D()(conv3)\n","\n","concat = concatenate([pool1,pool2,pool3])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSvOk7U78Z8B"},"source":["hidden = Dense(256,activation=tf.nn.relu)(concat)\n","dropout_hidden = Dropout(rate=0.5)(hidden)\n","#감정이 3가지 클래스로 분류 되므로 출력 노드를 3개로 설정\n","#최종 단계이므로 활성화함수 사용X\n","logits = Dense(5,name='logits')(dropout_hidden)\n","predictions = Dense(5,activation=tf.nn.softmax)(logits)\n","\n","#모델 생성\n","model = Model(inputs=Input_layer, outputs=predictions)\n","#모델 compile\n","model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z2IjdMG58m7n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6632b12-2d3c-4551-be84-e734c6042edb"},"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","filename = 'checkpoint-epoch-{}-batch-{}-trial-001.h5'.format(15, 256)\n","checkpoint = ModelCheckpoint(filename,monitor='val_loss',verbose=1,save_best_only=True,mode='auto')\n","earlystopping = EarlyStopping(monitor='val_loss',patience=2)\n","\n","#모델 생성\n","model = Model(inputs=Input_layer, outputs=predictions)\n","#모델 compile\n","model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","\n","#모델 summary\n","print(model.summary())\n","\n","\n","#모델 fit\n","num_epochs = 15 \n","history = model.fit(train_padded, y_train, epochs=num_epochs, batch_size=256, validation_split=0.1,callbacks=[checkpoint, earlystopping])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            [(None, 150)]        0                                            \n","__________________________________________________________________________________________________\n","embedding_6 (Embedding)         (None, 150, 256)     12378880    input_7[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 150, 256)     0           embedding_6[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_18 (Conv1D)              (None, 148, 256)     196864      dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","conv1d_19 (Conv1D)              (None, 147, 256)     262400      dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","conv1d_20 (Conv1D)              (None, 146, 256)     327936      dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","global_max_pooling1d_18 (Global (None, 256)          0           conv1d_18[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_19 (Global (None, 256)          0           conv1d_19[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_20 (Global (None, 256)          0           conv1d_20[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 768)          0           global_max_pooling1d_18[0][0]    \n","                                                                 global_max_pooling1d_19[0][0]    \n","                                                                 global_max_pooling1d_20[0][0]    \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 256)          196864      concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 256)          0           dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","logits (Dense)                  (None, 5)            1285        dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 5)            30          logits[0][0]                     \n","==================================================================================================\n","Total params: 13,364,259\n","Trainable params: 13,364,259\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/15\n","193/193 [==============================] - 52s 264ms/step - loss: 0.4793 - accuracy: 0.8343 - val_loss: 0.7155 - val_accuracy: 0.7350\n","\n","Epoch 00001: val_loss improved from inf to 0.71547, saving model to checkpoint-epoch-15-batch-256-trial-001.h5\n","Epoch 2/15\n","193/193 [==============================] - 50s 260ms/step - loss: 0.3736 - accuracy: 0.8691 - val_loss: 0.7428 - val_accuracy: 0.7412\n","\n","Epoch 00002: val_loss did not improve from 0.71547\n","Epoch 3/15\n","193/193 [==============================] - 50s 258ms/step - loss: 0.3063 - accuracy: 0.8913 - val_loss: 0.8015 - val_accuracy: 0.7281\n","\n","Epoch 00003: val_loss did not improve from 0.71547\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WanimbaYyoaM"},"source":["# predict values\n","import numpy as np\n","pred = model.predict(test_padded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUXnSQ9Gyoad"},"source":["# submission\n","from sklearn import datasets\n","sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n","sample_submission[['0','1','2','3','4']] = pred\n","sample_submission.to_csv('/content/submission.csv', index = False, encoding = 'utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZBoST1qlyoae"},"source":["p_val = np.zeros((train_padded.shape[0], 5))\n","p_val = model.predict(train_padded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2YMp3rFtyoaf","outputId":"58c8ba51-a333-499e-a2aa-db4904dcadc9"},"source":["from sklearn.metrics import accuracy_score, log_loss\n","print(accuracy_score(y_train, np.argmax(p_val, axis=1)) * 100)\n","print(log_loss(pd.get_dummies(y_train), p_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["91.89568706118355\n","0.25783785614027\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6wgU9_wL2Iyk"},"source":["# 3. 첫 번째 전처리와 baseline 모델링"]},{"cell_type":"code","metadata":{"id":"XBzwKGDK2P85"},"source":["vocab_size=len(list(set(word_list)))\n","embedding_dim = 256\n","max_length = 150\n","padding_type='post'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IN8g__vE2P86"},"source":["from keras_preprocessing.text import Tokenizer\n","#tokenizer에 fit \n","tokenizer = Tokenizer(num_words = vocab_size)\n","#, oov_token=oov_tok) \n","tokenizer.fit_on_texts(X_train) \n","word_index = tokenizer.word_index\n","vocab_size=len(word_index)+1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQNjkvt82P86","outputId":"acaae55f-b99d-49c8-b9bd-c976f3ab1d0e"},"source":["from keras_preprocessing.sequence import pad_sequences \n","#데이터를 sequence로 변환해주고 padding \n","train_sequences = tokenizer.texts_to_sequences(X_train) \n","train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length) \n","\n","test_sequences = tokenizer.texts_to_sequences(X_test) \n","test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n","\n","print(train_padded.shape, test_padded.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(54835, 150) (19617, 150)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VhcUhLfxHOJa"},"source":["# 가벼운 NLP모델 생성\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, 300, input_length=max_length),\n","    tf.keras.layers.GlobalAveragePooling1D(),\n","    tf.keras.layers.Dense(24, activation='relu'),\n","    tf.keras.layers.Dense(5, activation='softmax')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1a2U5WQ4HOJa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d4a9d04-97d4-43b1-9d34-26a714b553c5"},"source":["# compile model\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","# model summary\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_7 (Embedding)      (None, 150, 300)          14506500  \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 300)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 24)                7224      \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 5)                 125       \n","=================================================================\n","Total params: 14,513,849\n","Trainable params: 14,513,849\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gi2S6nLsHOJa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5e37f571-f215-4a1e-e31a-39b92a5aa9ef"},"source":["# fit model\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","filename = 'checkpoint-epoch-{}-batch-{}-trial-001.h5'.format(15, 256)\n","checkpoint = ModelCheckpoint(filename,monitor='val_loss',verbose=1,save_best_only=True,mode='auto')\n","earlystopping = EarlyStopping(monitor='val_loss',patience=2)\n","\n","num_epochs = 10\n","history = model.fit(train_padded, y_train, \n","                    epochs=num_epochs, verbose=2, \n","                    validation_split=0.2,callbacks=[checkpoint,earlystopping])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1371/1371 - 197s - loss: 1.2802 - accuracy: 0.4699 - val_loss: 0.9748 - val_accuracy: 0.6336\n","\n","Epoch 00001: val_loss improved from inf to 0.97483, saving model to checkpoint-epoch-15-batch-256-trial-001.h5\n","Epoch 2/10\n","1371/1371 - 194s - loss: 0.8154 - accuracy: 0.6947 - val_loss: 0.8038 - val_accuracy: 0.6999\n","\n","Epoch 00002: val_loss improved from 0.97483 to 0.80380, saving model to checkpoint-epoch-15-batch-256-trial-001.h5\n","Epoch 3/10\n","1371/1371 - 194s - loss: 0.6137 - accuracy: 0.7800 - val_loss: 0.7199 - val_accuracy: 0.7360\n","\n","Epoch 00003: val_loss improved from 0.80380 to 0.71993, saving model to checkpoint-epoch-15-batch-256-trial-001.h5\n","Epoch 4/10\n","1371/1371 - 195s - loss: 0.5011 - accuracy: 0.8185 - val_loss: 0.7759 - val_accuracy: 0.7046\n","\n","Epoch 00004: val_loss did not improve from 0.71993\n","Epoch 5/10\n","1371/1371 - 196s - loss: 0.4287 - accuracy: 0.8442 - val_loss: 0.7297 - val_accuracy: 0.7371\n","\n","Epoch 00005: val_loss did not improve from 0.71993\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hOVZilcTHOJa"},"source":["# predict values\n","pred = model.predict(test_padded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HhAJocEzHOJb"},"source":["# submission\n","sample_submission[['0','1','2','3','4']] = pred\n","sample_submission.to_csv('/content/submission.csv', index = False, encoding = 'utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFkEv3OJRQKj"},"source":["p_val = np.zeros((train_padded.shape[0], 5))\n","p_val = model.predict(train_padded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AkPC6VdNRmMZ","outputId":"68d84e65-b8e3-44a3-8396-529e79572fea"},"source":["p_val.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(54835, 5)"]},"metadata":{"tags":[]},"execution_count":184}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTzhD6tloTpr","outputId":"81b5f30a-176b-4f5a-a984-1eb8ea9a0beb"},"source":["print(log_loss(pd.get_dummies(y_train), p_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.43308831120319935\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LBPu1lbT3SXK"},"source":["# 4. 첫 번째 전처리와 CNN(1D CNN)(병렬화X)"]},{"cell_type":"code","metadata":{"id":"urbEsFrr4HUc"},"source":["vocab_size=len(list(set(word_list)))\n","embedding_dim = 256\n","max_length = 150\n","padding_type='post'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xaaNU7MT4HUc"},"source":["from keras_preprocessing.text import Tokenizer\n","#tokenizer에 fit \n","tokenizer = Tokenizer(num_words = vocab_size)\n","tokenizer.fit_on_texts(X_train) \n","word_index = tokenizer.word_index\n","vocab_size=len(word_index)+1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZB1BGqze4HUd","outputId":"983111af-cfa8-47f4-91f5-1f9e9480f513"},"source":["from keras_preprocessing.sequence import pad_sequences \n","#데이터를 sequence로 변환해주고 padding \n","train_sequences = tokenizer.texts_to_sequences(X_train) \n","train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length) \n","\n","test_sequences = tokenizer.texts_to_sequences(X_test) \n","test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n","\n","print(train_padded.shape, test_padded.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(54835, 150) (19617, 150)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZJwN-Tta7vfh"},"source":["데이터가 편항되어 있을 경우(몰려있을 경우) 단순 k-겹 교차검증을 사용하면 성능 평가가 잘 되지 않을 수 있다. 따라서 이럴 땐 stratified k-fold cross-validation을 사용"]},{"cell_type":"code","metadata":{"id":"dyTEclpT3Vq9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619686404975,"user_tz":-540,"elapsed":928,"user":{"displayName":"정유석","photoUrl":"","userId":"06335261930596017698"}},"outputId":"14ff1149-be66-4ab2-db93-ef9d3a01605b"},"source":["from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import StratifiedKFold # 이게 생각보다 효과가 좋다\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","\n","n_fold = 5\n","n_class = 5\n","seed = 42\n","\n","#cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n","\n","#def get_model():\n","model = Sequential([\n","                      Embedding(42331, 300, input_length=173),\n","                      Dropout(.5),\n","                      Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3),\n","                      Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3),    \n","                      GlobalMaxPooling1D(),\n","                      Dense(128, activation='relu'),\n","                      Dropout(.5),\n","                      Dense(n_class, activation='softmax')\n","      ])\n","    \n","    # compile model\n","model.compile(loss='categorical_crossentropy',\n","                  optimizer=Adam(learning_rate=.007))\n","model.summary()\n","  #return model"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 173, 300)          12699300  \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 173, 300)          0         \n","_________________________________________________________________\n","conv1d_8 (Conv1D)            (None, 56, 128)           268928    \n","_________________________________________________________________\n","conv1d_9 (Conv1D)            (None, 17, 128)           114816    \n","_________________________________________________________________\n","global_max_pooling1d_4 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 128)               16512     \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 5)                 645       \n","=================================================================\n","Total params: 13,100,201\n","Trainable params: 13,100,201\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwC929Tj4Xve","outputId":"549701fb-9ceb-4337-e8a3-a689a62017aa"},"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import plot_model, to_categorical\n","\n","p_val = np.zeros((train_padded.shape[0], n_class))\n","p_tst = np.zeros((test_padded.shape[0], n_class))\n","for i, (i_trn, i_val) in enumerate(cv.split(train_padded, y_train), 1):\n","    print(f'training model for CV #{i}')\n","    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n","                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n","\n","    clf = get_model()    \n","    clf.fit(train_padded[i_trn], \n","            to_categorical(y_train[i_trn]),\n","            validation_data=(train_padded[i_val], to_categorical(y_train[i_val])),\n","            epochs=10,\n","            batch_size=512,\n","            callbacks=[es])\n","    p_val[i_val, :] = clf.predict(train_padded[i_val])\n","    p_tst += clf.predict(test_padded) / n_fold"],"execution_count":null,"outputs":[{"output_type":"stream","text":["training model for CV #1\n","Epoch 1/10\n","86/86 [==============================] - 23s 262ms/step - loss: 1.4727 - val_loss: 0.9282\n","Epoch 2/10\n","86/86 [==============================] - 22s 258ms/step - loss: 0.7810 - val_loss: 0.7714\n","Epoch 3/10\n","86/86 [==============================] - 22s 254ms/step - loss: 0.4806 - val_loss: 0.8227\n","Epoch 4/10\n","86/86 [==============================] - 22s 251ms/step - loss: 0.3417 - val_loss: 0.9470\n","Epoch 5/10\n","86/86 [==============================] - 22s 251ms/step - loss: 0.2641 - val_loss: 1.0790\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","training model for CV #2\n","Epoch 1/10\n","86/86 [==============================] - 21s 232ms/step - loss: 1.4756 - val_loss: 0.9905\n","Epoch 2/10\n","86/86 [==============================] - 21s 249ms/step - loss: 0.8356 - val_loss: 0.8188\n","Epoch 3/10\n","86/86 [==============================] - 21s 249ms/step - loss: 0.5202 - val_loss: 0.8290\n","Epoch 4/10\n","86/86 [==============================] - 22s 251ms/step - loss: 0.3542 - val_loss: 0.9562\n","Epoch 5/10\n","86/86 [==============================] - 22s 252ms/step - loss: 0.2822 - val_loss: 1.0308\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","training model for CV #3\n","Epoch 1/10\n","86/86 [==============================] - 22s 251ms/step - loss: 1.4619 - val_loss: 1.0050\n","Epoch 2/10\n","86/86 [==============================] - 22s 253ms/step - loss: 0.8555 - val_loss: 0.8248\n","Epoch 3/10\n","86/86 [==============================] - 21s 249ms/step - loss: 0.5376 - val_loss: 0.8823\n","Epoch 4/10\n","86/86 [==============================] - 22s 251ms/step - loss: 0.3641 - val_loss: 0.9529\n","Epoch 5/10\n","86/86 [==============================] - 21s 249ms/step - loss: 0.2791 - val_loss: 1.1003\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","training model for CV #4\n","Epoch 1/10\n","86/86 [==============================] - 23s 255ms/step - loss: 1.4671 - val_loss: 0.9138\n","Epoch 2/10\n","86/86 [==============================] - 22s 253ms/step - loss: 0.7789 - val_loss: 0.7911\n","Epoch 3/10\n","86/86 [==============================] - 22s 252ms/step - loss: 0.4696 - val_loss: 0.8484\n","Epoch 4/10\n","86/86 [==============================] - 22s 251ms/step - loss: 0.3360 - val_loss: 0.9474\n","Epoch 5/10\n","86/86 [==============================] - 21s 249ms/step - loss: 0.2560 - val_loss: 1.1168\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n","training model for CV #5\n","Epoch 1/10\n","86/86 [==============================] - 23s 256ms/step - loss: 1.4462 - val_loss: 0.9384\n","Epoch 2/10\n","86/86 [==============================] - 22s 257ms/step - loss: 0.7564 - val_loss: 0.7986\n","Epoch 3/10\n","86/86 [==============================] - 22s 253ms/step - loss: 0.4669 - val_loss: 0.8834\n","Epoch 4/10\n","86/86 [==============================] - 22s 255ms/step - loss: 0.3263 - val_loss: 0.9659\n","Epoch 5/10\n","86/86 [==============================] - 22s 252ms/step - loss: 0.2501 - val_loss: 1.0919\n","Restoring model weights from the end of the best epoch.\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qG_J58NJ4g1c","outputId":"9f43c1b8-267f-49b8-ad9a-c2deb364124e"},"source":["print(accuracy_score(y_train, np.argmax(p_val, axis=1)) * 100)\n","print(log_loss(pd.get_dummies(y_train), p_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["70.06291602078964\n","0.8009387754080363\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy74q4QM6G2K","outputId":"33966b9a-0185-47b5-fd85-8d7501117e81"},"source":["p_vals = np.zeros((train_padded.shape[0], n_class))\n","p_vals = clf.predict(train_padded)\n","print(log_loss(pd.get_dummies(y_train), p_vals))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.49436745272889177\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"AiSlVRe8_Uki","outputId":"77667bc4-aa2a-47fa-8293-b0861df31789"},"source":["sample_file = pd.read_csv(\"/content/sample_submission.csv\")\n","sample_file.iloc[:,1]=p_tst[:,0]\n","sample_file.iloc[:,2]=p_tst[:,1]\n","sample_file.iloc[:,3]=p_tst[:,2]\n","sample_file.iloc[:,4]=p_tst[:,3]\n","sample_file.iloc[:,5]=p_tst[:,4]\n","sample_file"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.113609</td>\n","      <td>0.287823</td>\n","      <td>2.626945e-01</td>\n","      <td>2.945273e-01</td>\n","      <td>4.134656e-02</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.388333</td>\n","      <td>0.192807</td>\n","      <td>1.113744e-01</td>\n","      <td>7.393887e-02</td>\n","      <td>2.335467e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.994642</td>\n","      <td>0.000699</td>\n","      <td>1.229588e-04</td>\n","      <td>1.832762e-04</td>\n","      <td>4.352240e-03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.004923</td>\n","      <td>0.001444</td>\n","      <td>8.893510e-01</td>\n","      <td>4.424946e-03</td>\n","      <td>9.985697e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.584778</td>\n","      <td>0.032570</td>\n","      <td>7.485954e-02</td>\n","      <td>7.362310e-02</td>\n","      <td>2.341695e-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19612</th>\n","      <td>19612</td>\n","      <td>0.000042</td>\n","      <td>0.999958</td>\n","      <td>7.241811e-09</td>\n","      <td>2.745718e-07</td>\n","      <td>1.925731e-08</td>\n","    </tr>\n","    <tr>\n","      <th>19613</th>\n","      <td>19613</td>\n","      <td>0.108885</td>\n","      <td>0.032430</td>\n","      <td>2.895139e-01</td>\n","      <td>1.823461e-02</td>\n","      <td>5.509355e-01</td>\n","    </tr>\n","    <tr>\n","      <th>19614</th>\n","      <td>19614</td>\n","      <td>0.000021</td>\n","      <td>0.999978</td>\n","      <td>6.969800e-08</td>\n","      <td>1.554467e-07</td>\n","      <td>1.744547e-08</td>\n","    </tr>\n","    <tr>\n","      <th>19615</th>\n","      <td>19615</td>\n","      <td>0.005660</td>\n","      <td>0.992143</td>\n","      <td>6.089556e-04</td>\n","      <td>1.316860e-03</td>\n","      <td>2.711600e-04</td>\n","    </tr>\n","    <tr>\n","      <th>19616</th>\n","      <td>19616</td>\n","      <td>0.824340</td>\n","      <td>0.001030</td>\n","      <td>5.789201e-02</td>\n","      <td>2.685773e-03</td>\n","      <td>1.140521e-01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>19617 rows × 6 columns</p>\n","</div>"],"text/plain":["       index         0         1             2             3             4\n","0          0  0.113609  0.287823  2.626945e-01  2.945273e-01  4.134656e-02\n","1          1  0.388333  0.192807  1.113744e-01  7.393887e-02  2.335467e-01\n","2          2  0.994642  0.000699  1.229588e-04  1.832762e-04  4.352240e-03\n","3          3  0.004923  0.001444  8.893510e-01  4.424946e-03  9.985697e-02\n","4          4  0.584778  0.032570  7.485954e-02  7.362310e-02  2.341695e-01\n","...      ...       ...       ...           ...           ...           ...\n","19612  19612  0.000042  0.999958  7.241811e-09  2.745718e-07  1.925731e-08\n","19613  19613  0.108885  0.032430  2.895139e-01  1.823461e-02  5.509355e-01\n","19614  19614  0.000021  0.999978  6.969800e-08  1.554467e-07  1.744547e-08\n","19615  19615  0.005660  0.992143  6.089556e-04  1.316860e-03  2.711600e-04\n","19616  19616  0.824340  0.001030  5.789201e-02  2.685773e-03  1.140521e-01\n","\n","[19617 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":211}]},{"cell_type":"code","metadata":{"id":"HDVrh1hy4t69"},"source":["sample_file.to_csv('/content/submission.csv', index = False, encoding = 'utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fXGAeIkB5yW"},"source":[""],"execution_count":null,"outputs":[]}]}